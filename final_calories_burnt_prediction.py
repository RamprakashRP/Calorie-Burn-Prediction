# -*- coding: utf-8 -*-
"""Final Calories Burnt Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u2mvjgb5yuBgOzHTEX0zIjraBYEwKN_t

Importing the Dependencies
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.metrics import recall_score, f1_score
from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn import metrics

"""Data Collection & Processing"""

# loading the data from csv file to a Pandas DataFrame
calories = pd.read_csv('/content/calories.csv')

# print the first 5 rows of the dataframe
calories.head()

exercise_data = pd.read_csv('/content/exercise.csv')

exercise_data.head()

"""Combining the two Dataframes"""

calories_data = pd.concat([exercise_data, calories['Calories']], axis=1)

calories_data.head()

# checking the number of rows and columns
calories_data.shape

# getting some informations about the data
calories_data.info()

# checking for missing values
calories_data.isnull().sum()

"""Data Analysis"""

# get some statistical measures about the data
calories_data.describe()

"""Data Visualization"""

sns.set()

# plotting the gender column in count plot
sns.countplot(calories_data['Gender'])

# finding the distribution of "Age" column
sns.distplot(calories_data['Age'])

# finding the distribution of "Height" column
sns.distplot(calories_data['Height'])

# finding the distribution of "Weight" column
sns.distplot(calories_data['Weight'])

"""Finding the Correlation in the dataset

1. Positive Correlation
2. Negative Correlation
"""

correlation = calories_data.select_dtypes(include=[float, int]).corr()

# constructing a heatmap to understand the correlation

plt.figure(figsize=(10,10))
sns.heatmap(correlation, cbar=True, square=True, fmt='.1f', annot=True, annot_kws={'size':8}, cmap='Blues')

"""Converting the text data to numerical values"""

calories_data.replace({"Gender":{'male':0,'female':1}}, inplace=True)

calories_data.head()

"""Separating features and Target"""

X = calories_data.drop(columns=['User_ID','Calories'], axis=1)
Y = calories_data['Calories']

print(X)

print(Y)

"""Splitting the data into training data and Test data"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)

print(X.shape, X_train.shape, X_test.shape)

"""Model Training

XGBoost Regressor
"""

# loading the model
model = XGBRegressor()

# training the model with X_train
model.fit(X_train, Y_train)

"""Evaluation

Prediction on Test Data
"""

test_data_prediction = model.predict(X_test)

print(test_data_prediction)

"""XGBoost Regression"""

# Train the XGBoost Regressor
model_xgb = XGBRegressor()
model_xgb.fit(X_train, Y_train)

# Predict on the test data using XGBoost
test_data_prediction_xgb = model_xgb.predict(X_test)

# Performance metrics for XGBoost
r2_error_xgb = metrics.r2_score(Y_test, test_data_prediction_xgb)
mae_xgb = metrics.mean_absolute_error(Y_test, test_data_prediction_xgb)
mse_xgb = metrics.mean_squared_error(Y_test, test_data_prediction_xgb)
rmse_xgb = np.sqrt(mse_xgb)
accuracy_xgb = 100 - (mae_xgb * 100 / sum(Y_test))

threshold = 200  # You can adjust this value depending on the context
predicted_classes = (test_data_prediction > threshold).astype(int)

# Convert the true target values to binary
true_classes = (Y_test > threshold).astype(int)

# Calculate recall
recall = recall_score(true_classes, predicted_classes)
print(f"XGBoost - Recall: {recall}")

# Calculate F1-score
f1 = f1_score(true_classes, predicted_classes)
print(f"XGBoost - F1-score: {f1}")

print("XGBoost - R-squared: ", r2_error_xgb)
print(f"XGBoost - MAE: {mae_xgb}, MSE: {mse_xgb}, RMSE: {rmse_xgb}, Accuracy: {accuracy_xgb}%")

# Plotting actual vs predicted values for XGBoost
plt.figure(figsize=(8, 6))
plt.scatter(Y_test, test_data_prediction_xgb, color='blue')  # Scatter plot for XGBoost predictions
plt.plot([min(Y_test), max(Y_test)], [min(Y_test), max(Y_test)], color='red', linestyle='--')  # Perfect prediction line
plt.xlabel("Actual Calories")
plt.ylabel("Predicted Calories")
plt.title("XGBoost: Actual vs. Predicted Calories")
plt.show()

"""Linear Regression"""

# Train the Linear Regression model
model_lr = LinearRegression()
model_lr.fit(X_train, Y_train)

# Predict on the test data
test_data_prediction_lr = model_lr.predict(X_test)

# Calculate R-squared error for Linear Regression
r2_error_lr = metrics.r2_score(Y_test, test_data_prediction_lr)

# Additional performance metrics for Linear Regression
mae_lr = metrics.mean_absolute_error(Y_test, test_data_prediction_lr)
mse_lr = metrics.mean_squared_error(Y_test, test_data_prediction_lr)
rmse_lr = np.sqrt(mse_lr)

# Calculate accuracy for Linear Regression
accuracy_lr = 100 - (mae_lr * 100 / sum(Y_test))

threshold = 200  # You can adjust this value depending on the context
predicted_classes = (test_data_prediction > threshold).astype(int)

# Convert the true target values to binary
true_classes = (Y_test > threshold).astype(int)

# Calculate recall
recall = recall_score(true_classes, predicted_classes)
print(f"Linear Regression - Recall: {recall}")

# Calculate F1-score
f1 = f1_score(true_classes, predicted_classes)
print(f"Linear Regression - F1-score: {f1}")

print("Linear Regression - R squared error: ", r2_error_lr)
print(f"Linear Regression - MAE: {mae_lr}, MSE: {mse_lr}, RMSE: {rmse_lr}, Accuracy: {accuracy_lr}%")

# Plotting actual vs predicted values
plt.figure(figsize=(8, 6))  # Adjust figure size
plt.scatter(Y_test, test_data_prediction_lr, color='blue')  # Scatter plot
plt.plot([min(Y_test), max(Y_test)], [min(Y_test), max(Y_test)], color='red', linestyle='--')  # Perfect prediction line
plt.xlabel("Actual Calories")
plt.ylabel("Predicted Calories")
plt.title("Linear Regression: Actual vs. Predicted Calories")
plt.show()

"""SVM Regression"""

# Train the SVM model (Support Vector Regression)
model_svm = SVR(kernel='rbf')  # You can experiment with different kernels like 'linear', 'poly', 'rbf'
model_svm.fit(X_train, Y_train)

# Predict on the test data using SVM
test_data_prediction_svm = model_svm.predict(X_test)

# Performance metrics for SVM
r2_error_svm = metrics.r2_score(Y_test, test_data_prediction_svm)
mae_svm = metrics.mean_absolute_error(Y_test, test_data_prediction_svm)
mse_svm = metrics.mean_squared_error(Y_test, test_data_prediction_svm)
rmse_svm = np.sqrt(mse_svm)
accuracy_svm = 100 - (mae_svm * 100 / sum(Y_test))

threshold = 200
predicted_classes = (test_data_prediction > threshold).astype(int)

# Convert the true target values to binary
true_classes = (Y_test > threshold).astype(int)

# Calculate recall
recall = recall_score(true_classes, predicted_classes)
print(f"SVM - Recall: {recall}")

# Calculate F1-score
f1 = f1_score(true_classes, predicted_classes)
print(f"SVM - F1-score: {f1}")

print("SVM - R-squared: ", r2_error_svm)
print(f"SVM - MAE: {mae_svm}, MSE: {mse_svm}, RMSE: {rmse_svm}, Accuracy: {accuracy_svm}%")

# Plotting actual vs predicted values for SVM
plt.figure(figsize=(8, 6))
plt.scatter(Y_test, test_data_prediction_svm, color='green')  # Scatter plot for SVM predictions
plt.plot([min(Y_test), max(Y_test)], [min(Y_test), max(Y_test)], color='red', linestyle='--')  # Perfect prediction line
plt.xlabel("Actual Calories")
plt.ylabel("Predicted Calories")
plt.title("SVM: Actual vs. Predicted Calories")
plt.show()

"""Random Forest Regression"""

# Train the Random Forest Regressor
model_rf = RandomForestRegressor(n_estimators=100, random_state=2)
model_rf.fit(X_train, Y_train)

# Predict on the test data using Random Forest
test_data_prediction_rf = model_rf.predict(X_test)

# Calculate performance metrics for Random Forest
r2_error_rf = metrics.r2_score(Y_test, test_data_prediction_rf)
mae_rf = metrics.mean_absolute_error(Y_test, test_data_prediction_rf)
mse_rf = metrics.mean_squared_error(Y_test, test_data_prediction_rf)
rmse_rf = np.sqrt(mse_rf)

# Calculate accuracy for Random Forest
accuracy_rf = 100 - (mae_rf * 100 / sum(Y_test))

threshold = 200  # You can adjust this value depending on the context
predicted_classes = (test_data_prediction > threshold).astype(int)

# Convert the true target values to binary
true_classes = (Y_test > threshold).astype(int)

# Calculate recall
recall = recall_score(true_classes, predicted_classes)
print(f"Random Forest - Recall: {recall}")

# Calculate F1-score
f1 = f1_score(true_classes, predicted_classes)
print(f"Random Forest - F1-score: {f1}")

# Print the performance metrics
print("Random Forest - R-squared: ", r2_error_rf)
print(f"Random Forest - MAE: {mae_rf}, MSE: {mse_rf}, RMSE: {rmse_rf}, Accuracy: {accuracy_rf}%")

# Plotting actual vs predicted values for Random Forest
plt.figure(figsize=(8, 6))  # Adjust figure size for better visualization
plt.scatter(Y_test, test_data_prediction_rf, color='green')  # Scatter plot for Random Forest predictions
plt.plot([min(Y_test), max(Y_test)], [min(Y_test), max(Y_test)], color='red', linestyle='--')  # Perfect prediction line
plt.xlabel("Actual Calories")
plt.ylabel("Predicted Calories")
plt.title("Random Forest: Actual vs. Predicted Calories")
plt.show()

"""Overall code"""

# Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from xgboost import XGBRegressor
from sklearn import metrics
from sklearn.metrics import recall_score, f1_score

# Load datasets
calories = pd.read_csv('/content/calories.csv')
exercise_data = pd.read_csv('/content/exercise.csv')

# Merge datasets
calories_data = pd.concat([exercise_data, calories['Calories']], axis=1)

# Preprocessing
calories_data.replace({"Gender": {'male': 0, 'female': 1}}, inplace=True)

# Split the data into features (X) and target (Y)
X = calories_data.drop(columns=['User_ID', 'Calories'], axis=1)
Y = calories_data['Calorie']
# Split the dataset into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)

# Initialize Models
xgb_model = XGBRegressor()
rf_model = RandomForestRegressor()
lr_model = LinearRegression()
svr_model = SVR()

# Function to calculate accuracy
def calculate_accuracy(Y_test, predictions):
    mae = metrics.mean_absolute_error(Y_test, predictions)
    accuracy = 100 - (mae * 100 / sum(Y_test))
    return accuracy

# Function to calculate recall and F1-score for regression
def calculate_classification_metrics(Y_test, predictions, threshold):
    # Convert continuous predictions to binary classes based on threshold
    predicted_classes = (predictions > threshold).astype(int)
    actual_classes = (Y_test > threshold).astype(int)

    # Calculate recall and F1 score
    recall = recall_score(actual_classes, predicted_classes)
    f1 = f1_score(actual_classes, predicted_classes)

    return recall, f1

# Set a threshold for classification (you can adjust this based on your data)
threshold = 200

# Train and Evaluate XGBoost
xgb_model.fit(X_train, Y_train)
xgb_pred = xgb_model.predict(X_test)
mae_xgb = metrics.mean_absolute_error(Y_test, xgb_pred)
r2_xgb = metrics.r2_score(Y_test, xgb_pred)
accuracy_xgb = calculate_accuracy(Y_test, xgb_pred)
recall_xgb, f1_xgb = calculate_classification_metrics(Y_test, xgb_pred, threshold)
print(f"XGBoost - MAE: {mae_xgb}, R-squared: {r2_xgb}, Accuracy: {accuracy_xgb}%, Recall: {recall_xgb}, F1 Score: {f1_xgb}")

# Train and Evaluate Random Forest
rf_model.fit(X_train, Y_train)
rf_pred = rf_model.predict(X_test)
mae_rf = metrics.mean_absolute_error(Y_test, rf_pred)
r2_rf = metrics.r2_score(Y_test, rf_pred)
accuracy_rf = calculate_accuracy(Y_test, rf_pred)
recall_rf, f1_rf = calculate_classification_metrics(Y_test, rf_pred, threshold)
print(f"Random Forest - MAE: {mae_rf}, R-squared: {r2_rf}, Accuracy: {accuracy_rf}%, Recall: {recall_rf}, F1 Score: {f1_rf}")

# Train and Evaluate Linear Regression
lr_model.fit(X_train, Y_train)
lr_pred = lr_model.predict(X_test)
mae_lr = metrics.mean_absolute_error(Y_test, lr_pred)
r2_lr = metrics.r2_score(Y_test, lr_pred)
accuracy_lr = calculate_accuracy(Y_test, lr_pred)
recall_lr, f1_lr = calculate_classification_metrics(Y_test, lr_pred, threshold)
print(f"Linear Regression - MAE: {mae_lr}, R-squared: {r2_lr}, Accuracy: {accuracy_lr}%, Recall: {recall_lr}, F1 Score: {f1_lr}")

# Train and Evaluate Support Vector Regressor
svr_model.fit(X_train, Y_train)
svr_pred = svr_model.predict(X_test)
mae_svr = metrics.mean_absolute_error(Y_test, svr_pred)
r2_svr = metrics.r2_score(Y_test, svr_pred)
accuracy_svr = calculate_accuracy(Y_test, svr_pred)
recall_svr, f1_svr = calculate_classification_metrics(Y_test, svr_pred, threshold)
print(f"SVM - MAE: {mae_svr}, R-squared: {r2_svr}, Accuracy: {accuracy_svr}%, Recall: {recall_svr}, F1 Score: {f1_svr}")

# Plot actual vs predicted for all models
plt.figure(figsize=(15, 10))

# XGBoost
plt.subplot(2, 2, 1)
plt.scatter(Y_test, xgb_pred, color='blue')
plt.plot([min(Y_test), max(Y_test)], [min(Y_test), max(Y_test)], color='red', linestyle='--')
plt.title("XGBoost: Actual vs. Predicted")
plt.xlabel("Actual Calories")
plt.ylabel("Predicted Calories")
9*--9**999666666
# Random Forest
plt.subplot(2, 2, 2)
plt.scatter(Y_test, rf_pred, color='green')
plt.plot([min(Y_test), max(Y_test)], [min(Y_test), max(Y_test)], color='red', linestyle='--')
plt.title("Random Forest: Actual vs. Predicted")
plt.xlabel("Actual Calories")
plt.ylabel("Predicted Calories")

# Linear Regression
plt.subplot(2, 2, 3)
plt.scatter(Y_test, lr_pred, color='orange')
plt.plot([min(Y_test), max(Y_test)], [min(Y_test), max(Y_test)], color='red', linestyle='--')
plt.title("Linear Regression: Actual vs. Predicted")
plt.xlabel("Actual Calories")
plt.ylabel("Predicted Calories")

# SVM
plt.subplot(2, 2, 4)
plt.scatter(Y_test, svr_pred, color='purple')
plt.plot([min(Y_test), max(Y_test)], [min(Y_test), max(Y_test)], color='red', linestyle='--')
plt.title("SVM: Actual vs. Predicted")
plt.xlabel("Actual Calories")
plt.ylabel("Predicted Calories")

plt.tight_layout()
plt.show()

def predict_calories(input_data):
    # Convert input data into a numpy array and reshape
    input_data_as_numpy_array = np.array(input_data).reshape(1, -1)

    # Predict using XGBoost
    xgb_prediction = xgb_model.predict(input_data_as_numpy_array)
    print(f"Predicted Calories (XGBoost): {xgb_prediction[0]}")

    # Predict using Random Forest
    rf_prediction = rf_model.predict(input_data_as_numpy_array)
    print(f"Predicted Calories (Random Forest): {rf_prediction[0]}")

    # Predict using Linear Regression
    lr_prediction = lr_model.predict(input_data_as_numpy_array)
    print(f"Predicted Calories (Linear Regression): {lr_prediction[0]}")

    # Predict using SVM
    svr_prediction = svr_model.predict(input_data_as_numpy_array)
    print(f"Predicted Calories (SVM): {svr_prediction[0]}")

# Example User Input
# Gender: male (0), Age: 25, Height: 175, Weight: 70, Duration: 30, Heart_Rate: 120, Body_Temp: 36.5
input_data = [0, 25, 175, 70, 30, 120, 36.5]

# Call the predictive function
predict_calories(input_data)

# Train and Evaluate Models
xgb_pred = xgb_model.predict(X_test)
rf_pred = rf_model.predict(X_test)
lr_pred = lr_model.predict(X_test)
svr_pred = svr_model.predict(X_test)